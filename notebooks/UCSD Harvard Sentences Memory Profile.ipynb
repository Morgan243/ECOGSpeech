{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f064429-ffc8-4623-8e89-a101f621361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecog_speech import datasets, experiments, result_parsing, utils, feature_processing, pipeline, plot_label_regions\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448dbf37-951b-4da9-af9c-b2f665a90c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvs_test_tuples = datasets.HarvardSentences.make_tuples_from_sets_str('UCSD-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02780c60-9665-4815-9214-ff68778ca039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41d6241-724f-4107-ab2e-126ee15a19b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:25:33,463 - ecog_speech.datasets.HarvardSentences.__attrs_post_init__:337 - DEBUG - preparing pipeline\n",
      "2022-07-21 20:25:33,466 - ecog_speech.datasets.HarvardSentences.__attrs_post_init__:340 - DEBUG - Available pipelines: ['random_sample', 'audio_gate', 'region_classification', 'region_classification_from_word_stim', 'audio_gate_speaking_only', 'default']\n",
      "2022-07-21 20:25:33,468 - ecog_speech.datasets.HarvardSentences.initialize:353 - INFO - 'region_classification' pipeline selected\n",
      "2022-07-21 20:25:33,469 - ecog_speech.datasets.HarvardSentences.initialize:367 - INFO - Loading data directly\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baee3c18d1ea41d78931c73c345b6b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:25:33,584 - ecog_speech.datasets.HarvardSentences.load_data:788 - INFO - -----------Subset: Data------------\n",
      "2022-07-21 20:25:33,584 - ecog_speech.datasets.HarvardSentences.load_data:789 - INFO - ---28-1-1-UCSD---\n",
      "2022-07-21 20:25:33,585 - ecog_speech.datasets.HarvardSentences.make_filename:1235 - INFO - Harvard sentences only uses location and patient identifiers\n",
      "2022-07-21 20:25:33,586 - ecog_speech.datasets.HarvardSentences.load_data:792 - DEBUG - Path : /home/morgan/Projects/CMSCResearch/ECOGSpeech/ecog_speech/../data/HarvardSentences/UCSD/Data/UCSD28_Task_1.mat\n",
      "2022-07-21 20:25:33,593 - ecog_speech.datasets.HarvardSentences.load_mat_from_path:757 - INFO - Couldn't load UCSD28_Task_1.mat with scipy (vers > 7.3?) - using package 'mat73' to load\n",
      "2022-07-21 20:25:50,180 - ecog_speech.datasets.HarvardSentences.load_data:795 - DEBUG - Matlab keys : ['EKG_signal', 'Labels', 'audio', 'fs_audio', 'fs_signal', 'label_contact_common', 'label_contact_r_a_s', 'sEEG_signal', 'start_stop_word_ms', 'stimcode']\n",
      "2022-07-21 20:25:50,194 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:45 - DEBUG - Accessing fs_signal\n",
      "2022-07-21 20:25:50,196 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:52 - DEBUG - Input source frequency, fs object: 1024.0\n",
      "2022-07-21 20:25:50,384 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:71 - INFO - sEEG_signal@1024, shape: (900001, 108), [(Timedelta('0 days 00:00:00'), Timedelta('0 days 00:14:38.906250'))]\n",
      "2022-07-21 20:25:50,385 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.transform:22 - DEBUG - Updated keys: {'signal', 'fs_signal'}\n",
      "2022-07-21 20:25:50,385 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:45 - DEBUG - Accessing fs_audio\n",
      "2022-07-21 20:25:50,386 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:52 - DEBUG - Input source frequency, fs object: 48000.0\n",
      "2022-07-21 20:25:51,300 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:71 - INFO - audio@48000, shape: (42187547,), [(Timedelta('0 days 00:00:00'), Timedelta('0 days 00:14:38.907208333'))]\n",
      "2022-07-21 20:25:51,301 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.transform:22 - DEBUG - Updated keys: {'audio', 'fs_audio'}\n",
      "2022-07-21 20:25:51,303 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:45 - DEBUG - Accessing fs_signal\n",
      "2022-07-21 20:25:51,304 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:52 - DEBUG - Input source frequency, fs object: 1024\n",
      "2022-07-21 20:25:51,329 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:71 - INFO - stimcode@1024, shape: (900001,), [(Timedelta('0 days 00:00:00'), Timedelta('0 days 00:14:38.906250'))]\n",
      "2022-07-21 20:25:51,331 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.transform:22 - DEBUG - Updated keys: {'stim', 'fs_signal'}\n",
      "2022-07-21 20:25:51,346 - ecog_speech.pipeline.ParseSensorRAS.transform:22 - DEBUG - Updated keys: {'sensor_ras_df', 'sensor_ras_coord_arr'}\n",
      "2022-07-21 20:25:52,058 - ecog_speech.pipeline.ExtractMFCC.transform:22 - DEBUG - Updated keys: {'audio_mel_spec'}\n",
      "2022-07-21 20:25:52,059 - ecog_speech.pipeline.IdentifyGoodAndBadSensors.process:90 - WARNING - Electrodes with key 'electrodes' not found among ['EKG_signal', 'Labels', 'audio', 'fs_audio', 'fs_signal', 'label_contact_common', 'label_contact_r_a_s', 'sEEG_signal', 'start_stop_word_ms', 'stimcode', 'signal', 'stim', 'sensor_ras_df', 'sensor_ras_coord_arr', 'audio_mel_spec'] - but on_missing=\"ignore\", so moving on\n",
      "2022-07-21 20:25:52,060 - ecog_speech.pipeline.IdentifyGoodAndBadSensors.transform:22 - DEBUG - Updated keys: {'good_sensor_columns', 'bad_sensor_columns'}\n",
      "2022-07-21 20:25:52,061 - ecog_speech.pipeline.SubsampleSignal.transform:22 - DEBUG - Updated keys: {'stim', 'signal', 'fs_signal'}\n",
      "2022-07-21 20:25:52,209 - ecog_speech.pipeline.SentCodeFromStartStopWordTimes.process:410 - WARNING - Sent code 45.0 has a time range more than a minute: 0 days 00:01:20.365234375\n",
      "2022-07-21 20:25:52,279 - ecog_speech.pipeline.SentCodeFromStartStopWordTimes.transform:22 - DEBUG - Updated keys: {'stim', 'sent_start_stop_time', 'word_start_stop_times'}\n",
      "2022-07-21 20:25:52,428 - ecog_speech.pipeline.NewNewMultiTaskStartStop.process:504 - WARNING - Sent code 20.0 has no future sentence dodes in front of it\n",
      "2022-07-21 20:25:52,930 - ecog_speech.pipeline.NewNewMultiTaskStartStop.transform:22 - DEBUG - Updated keys: {'word_start_stop_times'}\n",
      "2022-07-21 20:25:55,885 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'speaking_word_stim', 'speaking_word_stim_mask'}\n",
      "2022-07-21 20:25:58,858 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'listening_word_stim_mask', 'listening_word_stim'}\n",
      "2022-07-21 20:26:01,894 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'mouthing_word_stim', 'mouthing_word_stim_mask'}\n",
      "2022-07-21 20:26:04,899 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'imagining_word_stim', 'imagining_word_stim_mask'}\n",
      "2022-07-21 20:26:06,049 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'speaking_region_stim_mask', 'speaking_region_stim'}\n",
      "2022-07-21 20:26:07,262 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'listening_region_stim_mask', 'listening_region_stim'}\n",
      "2022-07-21 20:26:08,426 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'mouthing_region_stim_mask', 'mouthing_region_stim'}\n",
      "2022-07-21 20:26:09,574 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'imagining_region_stim', 'imagining_region_stim_mask'}\n",
      "2022-07-21 20:26:09,576 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-21 20:26:09,577 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af15b90e718b4da084f2fb908779458f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'speaking_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:26:59,517 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-21 20:26:59,518 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 0\n",
      "2022-07-21 20:26:59,519 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-21 20:26:59,519 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-21 20:26:59,520 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdfefc51bc2408f8d4b5ef7445ec529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'listening_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:27:49,033 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-21 20:27:49,034 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 1\n",
      "2022-07-21 20:27:49,035 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-21 20:27:49,035 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-21 20:27:49,036 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347b0328a1564695a7761dc6b5f1b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'mouthing_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:28:43,628 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-21 20:28:43,628 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 2\n",
      "2022-07-21 20:28:43,629 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-21 20:28:43,630 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-21 20:28:43,631 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b731db1ec9bd43e7ba5038ab79f664e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'imagining_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:29:34,597 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-21 20:29:34,598 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 3\n",
      "2022-07-21 20:29:34,599 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-21 20:29:34,601 - ecog_speech.datasets.HarvardSentences.initialize:397 - INFO - N samples per window: 256\n",
      "2022-07-21 20:29:34,603 - ecog_speech.datasets.HarvardSentences.initialize:417 - INFO - GOOD AND BAD SENSORS: {('UCSD', 28, 1, 1): ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107], None)}\n",
      "2022-07-21 20:29:34,616 - ecog_speech.datasets.HarvardSentences.initialize:434 - INFO - Selected 108 columns using union method: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107\n",
      "2022-07-21 20:29:34,618 - ecog_speech.datasets.HarvardSentences.initialize:450 - INFO - Processing participant ('UCSD', 28, 1, 1) index, having keys: [0, 1, 2, 3]\n",
      "2022-07-21 20:30:19,837 - ecog_speech.datasets.HarvardSentences.initialize:473 - INFO - word_start_stop_times found aligning all index start times to a sentence code\n",
      "2022-07-21 20:30:19,894 - ecog_speech.datasets.HarvardSentences.initialize:480 - INFO - Combining all of 1 index frames\n",
      "2022-07-21 20:30:19,914 - ecog_speech.datasets.HarvardSentences.initialize:484 - INFO - flatten_sensors_to_samples selected - creating channel/sensor labels for samples\n",
      "2022-07-21 20:30:19,962 - ecog_speech.datasets.HarvardSentences.initialize:489 - DEBUG - exploding sensor data - does this take a while?\n",
      "2022-07-21 20:30:22,463 - ecog_speech.datasets.HarvardSentences.initialize:494 - INFO - Converting dataframe to a flat list of key variables (self.flat_keys)\n",
      "2022-07-21 20:30:33,025 - ecog_speech.datasets.HarvardSentences.initialize:501 - INFO - Extracting mapping of (['label', 'sample_ix', 'channel', 'location', 'patient', 'session', 'trial'])->indices\n",
      "2022-07-21 20:30:33,027 - ecog_speech.datasets.HarvardSentences.initialize:507 - INFO - Length of flat index map: 21600000\n",
      "2022-07-21 20:30:33,028 - ecog_speech.datasets.HarvardSentences.initialize:511 - INFO - Selected 108 sensors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13e4aa95b1348e1a4a9fa14920b4c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying sensor selection:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:30:33,143 - ecog_speech.pipeline.ApplySensorSelection.process:142 - INFO - Selection of columns passed to sensor selection\n",
      "2022-07-21 20:30:33,248 - ecog_speech.pipeline.ApplySensorSelection.process:167 - INFO - Selecting columns in RAS coordinate data\n",
      "2022-07-21 20:30:33,252 - ecog_speech.pipeline.ApplySensorSelection.transform:22 - DEBUG - Updated keys: {'sensor_ras_df', 'bad_columns', 'signal', 'selected_columns', 'bad_sensor_method', 'sensor_ras_coord_arr'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /home/morgan/Projects/CMSCResearch/ECOGSpeech/ecog_speech/datasets.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "   345    358.6 MiB    358.6 MiB           1       def initialize(self):\n",
       "   346                                         \n",
       "   347                                                 # If nothing passed, use 'default' pipeline\n",
       "   348    358.6 MiB      0.0 MiB           1           if self.pre_processing_pipeline is None:\n",
       "   349                                                     self.logger.info(\"Default pipeline selected\")\n",
       "   350                                                     self.pipeline_f = self.pipeline_map['default']\n",
       "   351                                                 # If string passed, use it to select the pipeline in the map\n",
       "   352    358.6 MiB      0.0 MiB           1           elif isinstance(self.pre_processing_pipeline, str):\n",
       "   353    358.6 MiB      0.0 MiB           1               self.logger.info(f\"'{self.pre_processing_pipeline}' pipeline selected\")\n",
       "   354    358.6 MiB      0.0 MiB           1               self.pipeline_f = self.pipeline_map[self.pre_processing_pipeline]\n",
       "   355                                                 # Otherwise, just assume it will work, that a callable is passed\n",
       "   356                                                 # TODO: Check that pipeline_f is callable\n",
       "   357                                                 else:\n",
       "   358                                                     self.logger.info(f\"{str(self.pre_processing_pipeline)} pipeline passed directly\")\n",
       "   359                                                     self.pipeline_f = self.pre_processing_pipeline\n",
       "   360                                         \n",
       "   361    358.6 MiB      0.0 MiB           1           if isinstance(self.pipeline_f, Pipeline):\n",
       "   362    358.6 MiB      0.0 MiB           1               self.pipeline_obj = self.pipeline_f\n",
       "   363    358.6 MiB      0.0 MiB           1               self.pipeline_f = self.pipeline_obj.transform\n",
       "   364                                         \n",
       "   365                                                 # If no data sharing, then load and parse data from scratch\n",
       "   366    358.6 MiB      0.0 MiB           1           if self.data_from is None:\n",
       "   367    358.6 MiB      0.0 MiB           1               self.logger.info(\"Loading data directly\")\n",
       "   368                                                     # Leave this here for now...\n",
       "   369                                                     # self.mfcc_m = torchaudio.transforms.MFCC(self.default_audio_sample_rate,\n",
       "   370                                                     #                                         self.num_mfcc)\n",
       "   371                                         \n",
       "   372                                                     ## Data loading ##\n",
       "   373                                                     # - Load the data, parsing into pandas data frame/series types\n",
       "   374                                                     # - Only minimal processing into Python objects done here\n",
       "   375    358.8 MiB      0.1 MiB           1               data_iter = tqdm(self.patient_tuples, desc=\"Loading data\")\n",
       "   376   1509.2 MiB   1150.4 MiB           7               mat_data_maps = {l_p_s_t_tuple: self.load_data(*l_p_s_t_tuple,\n",
       "   377                                                                                                    # sensor_columns=self.sensor_columns,\n",
       "   378                                                                                                    # IMPORTANT: Don't parse data yet\n",
       "   379                                                                                                    # parse_mat_data=False,\n",
       "   380    358.8 MiB      0.0 MiB           1                                                              subset=self.data_subset)\n",
       "   381    358.8 MiB      0.0 MiB           2                                for l_p_s_t_tuple in data_iter}\n",
       "   382                                         \n",
       "   383                                                     #  Important processing  #\n",
       "   384                                                     # - Process each subject in data map through pipeline func\n",
       "   385   1509.2 MiB      0.0 MiB           1               self.sample_index_maps = dict()\n",
       "   386   1509.2 MiB      0.0 MiB           1               self.data_maps = dict()\n",
       "   387                                         \n",
       "   388   2742.4 MiB      0.0 MiB           2               for k, dmap in mat_data_maps.items():\n",
       "   389                                                         # Run the pipeline, mutating/modifying the data map for this patient trial\n",
       "   390   2742.4 MiB   1233.2 MiB           1                   res_dmap = self.pipeline_f(dmap)\n",
       "   391   2742.4 MiB      0.0 MiB           1                   self.sample_index_maps[k] = res_dmap['sample_index_map']\n",
       "   392                                                         # THe first data map sets the sampling frequency fs\n",
       "   393                                                         # self.fs_signal = getattr(self, 'fs_signal', res_dmap[self.mat_d_keys['signal_fs']])\n",
       "   394   2742.4 MiB      0.0 MiB           1                   self.fs_signal = res_dmap[self.mat_d_keys['signal_fs']] if self.fs_signal is None else self.fs_signal\n",
       "   395                                         \n",
       "   396   2742.4 MiB      0.0 MiB           1                   self.n_samples_per_window = getattr(self, 'n_samples_per_window', res_dmap['n_samples_per_window'])\n",
       "   397   2742.4 MiB      0.0 MiB           1                   self.logger.info(f\"N samples per window: {self.n_samples_per_window}\")\n",
       "   398                                         \n",
       "   399   2742.4 MiB      0.0 MiB           1                   if self.fs_signal != res_dmap[self.mat_d_keys['signal_fs']]:\n",
       "   400                                                             raise ValueError(\"Mismatch fs (%s!=%s) on %s\" % (self.fs_signal, res_dmap['fs_signal'], str(k)))\n",
       "   401                                         \n",
       "   402   2742.4 MiB      0.0 MiB           1                   self.data_maps[k] = res_dmap\n",
       "   403                                         \n",
       "   404                                                     ###\n",
       "   405                                                     # Sensor selection logic - based on the patients loaded - which sensors do we use?\n",
       "   406   2742.4 MiB      0.0 MiB           1               if self.sensor_columns is None or isinstance(self.sensor_columns, str):\n",
       "   407                                                         # good_and_bad_tuple_d = {l_p_s_t_tuple: self.identify_good_and_bad_sensors(mat_d, self.sensor_columns)\n",
       "   408                                                         #                            for l_p_s_t_tuple, mat_d in mat_data_maps.items()}\n",
       "   409   2742.4 MiB      0.0 MiB           6                   good_and_bad_tuple_d = {l_p_s_t_tuple: (mat_d['good_sensor_columns'], mat_d['bad_sensor_columns'])\n",
       "   410   2742.4 MiB      0.0 MiB           2                                           for l_p_s_t_tuple, mat_d in self.data_maps.items()}\n",
       "   411                                         \n",
       "   412   2742.4 MiB      0.0 MiB           5                   good_and_bad_tuple_d = {\n",
       "   413   2742.4 MiB      0.0 MiB           2                       k: (set(gs) if gs else (list(range(self.data_maps[k][self.mat_d_keys['signal']].shape[1]))),\n",
       "   414   2742.4 MiB      0.0 MiB           1                           bs)\n",
       "   415   2742.4 MiB      0.0 MiB           2                       for k, (gs, bs) in good_and_bad_tuple_d.items()}\n",
       "   416                                         \n",
       "   417   2742.4 MiB      0.0 MiB           1                   self.logger.info(\"GOOD AND BAD SENSORS: \" + str(good_and_bad_tuple_d))\n",
       "   418   2742.4 MiB      0.0 MiB           1                   self.sensor_columns = 'union' if self.sensor_columns is None else self.sensor_columns\n",
       "   419                                         \n",
       "   420                                                         # UNION: Select all good sensors from all inputs, zeros will be filled for those missing\n",
       "   421   2742.4 MiB      0.0 MiB           1                   if self.sensor_columns == 'union':\n",
       "   422   2742.4 MiB      0.0 MiB         112                       self.selected_columns = sorted(list({_gs for k, (gs, bs) in good_and_bad_tuple_d.items()\n",
       "   423   2742.4 MiB      0.0 MiB         109                                                            for _gs in gs}))\n",
       "   424                                                         # INTERSECTION: Select only sensors that are rated good in all inputs\n",
       "   425                                                         elif self.sensor_columns == 'intersection' or self.sensor_columns == 'valid':\n",
       "   426                                                             s = [set(gs) for k, (gs, bs) in good_and_bad_tuple_d.items()]\n",
       "   427                                                             self.selected_columns = sorted(list(s[0].intersection(*s[1:])))\n",
       "   428                                         \n",
       "   429                                                         # elif self.sensor_columns == 'all':\n",
       "   430                                                         else:\n",
       "   431                                                             raise ValueError(\"Unknown snsor columns argument: \" + str(self.sensor_columns))\n",
       "   432                                                         # print(\"Selected columns with -%s- method: %s\"\n",
       "   433                                                         #      % (self.sensor_columns, \", \".join(map(str, self.selected_columns))) )\n",
       "   434   2742.4 MiB      0.0 MiB           2                   self.logger.info(f\"Selected {len(self.selected_columns)} columns using {self.sensor_columns} method: \"\n",
       "   435   2742.4 MiB      0.0 MiB           1                                    f\"{', '.join(map(str, self.selected_columns))}\")\n",
       "   436                                                         #self.logger.info(\"Selected columns with -%s- method: %s\"\n",
       "   437                                                         #                 % (self.sensor_columns, \", \".join(map(str, self.selected_columns))))\n",
       "   438                                                     else:\n",
       "   439                                                         self.selected_columns = self.sensor_columns\n",
       "   440                                         \n",
       "   441   2742.4 MiB      0.0 MiB           1               self.sensor_count = len(self.selected_columns)\n",
       "   442                                         \n",
       "   443                                                     # ### New Version ###\n",
       "   444   2742.4 MiB      0.0 MiB           1               sample_ix_df_l = list()\n",
       "   445   2742.4 MiB      0.0 MiB           2               key_col_dtypes = {'label': 'int8', 'sample_ix': 'int32', 'location': 'string',\n",
       "   446   2742.4 MiB      0.0 MiB           1                                'patient': 'int8', 'session': 'int8', 'trial': 'int8'}\n",
       "   447   2742.4 MiB      0.0 MiB           1               key_cols = list(key_col_dtypes.keys())\n",
       "   448                                         \n",
       "   449   2965.4 MiB      0.0 MiB           2               for l_p_s_t, index_map in self.sample_index_maps.items():\n",
       "   450   2742.4 MiB      0.0 MiB           1                   self.logger.info(f\"Processing participant {l_p_s_t} index, having keys: {list(index_map.keys())}\")\n",
       "   451   2742.4 MiB      0.0 MiB           1                   _data_map = self.data_maps[l_p_s_t]\n",
       "   452                                         \n",
       "   453                                                         #self.logger.info(f\"Creating participants index frame: {l_p_s_t}\")\n",
       "   454   2742.4 MiB      0.0 MiB           1                   patient_ixes = list()\n",
       "   455                                         \n",
       "   456   2742.4 MiB      0.0 MiB           1                   cols = key_cols + ['start_t', 'stop_t', 'indices']\n",
       "   457                                         \n",
       "   458   2742.4 MiB      0.0 MiB           1                   key_l = list(l_p_s_t)\n",
       "   459                                         \n",
       "   460   2919.0 MiB    166.0 MiB      200008                   patient_ixes += [tuple([label_code, ix_i] + key_l + [_ix.min(), _ix.max(), _ix])\n",
       "   461   2874.7 MiB      0.0 MiB           5                                    for label_code, indices_l in index_map.items()\n",
       "   462   2919.0 MiB     10.6 MiB      200004                                    for ix_i, _ix in enumerate(indices_l)]\n",
       "   463                                         \n",
       "   464   2965.3 MiB     46.3 MiB           1                   p_ix_df = pd.DataFrame(patient_ixes, columns=cols)\n",
       "   465   2965.3 MiB      0.0 MiB           1                   p_ix_df = p_ix_df.astype(key_col_dtypes)\n",
       "   466                                                         # Store a numeric index into underlying numpy array for faster indexing\n",
       "   467   2965.3 MiB      0.0 MiB           1                   if 'signal' in _data_map:\n",
       "   468   2965.3 MiB      0.0 MiB           1                       signal_df = _data_map['signal']\n",
       "   469   2965.3 MiB      0.0 MiB           1                       p_ix_df['start_ix'] = signal_df.index.get_indexer(p_ix_df.start_t)\n",
       "   470                                         \n",
       "   471                                                         # #TODO: Is this still necessary? Determining the sentence code for every window sample from scratch\n",
       "   472   2965.3 MiB      0.0 MiB           1                   if 'word_start_stop_times' in self.data_maps[l_p_s_t]:\n",
       "   473   2965.3 MiB      0.0 MiB           1                       self.logger.info(f\"word_start_stop_times found aligning all index start times to a sentence code\")\n",
       "   474   2965.3 MiB      0.0 MiB           1                       wsst_df = self.data_maps[l_p_s_t]['word_start_stop_times']\n",
       "   475   2965.3 MiB      0.0 MiB           1                       nearest_ixes = wsst_df.index.get_indexer(p_ix_df.start_t, method='nearest')\n",
       "   476   2965.4 MiB      0.1 MiB           1                       p_ix_df['sent_code'] = wsst_df.iloc[nearest_ixes].stim_sentcode.values\n",
       "   477                                         \n",
       "   478   2965.4 MiB      0.0 MiB           1                   sample_ix_df_l.append(p_ix_df)\n",
       "   479                                         \n",
       "   480   2965.4 MiB      0.0 MiB           1               self.logger.info(f\"Combining all of {len(sample_ix_df_l)} index frames\")\n",
       "   481   2966.1 MiB      0.8 MiB           1               self.sample_ix_df = pd.concat(sample_ix_df_l).reset_index(drop=True)\n",
       "   482   2966.1 MiB      0.0 MiB           1               self.k_select_offset = 2\n",
       "   483   2966.1 MiB      0.0 MiB           1               if self.flatten_sensors_to_samples:\n",
       "   484   2966.1 MiB      0.0 MiB           1                   self.logger.info(f\"flatten_sensors_to_samples selected - creating channel/sensor labels for samples\")\n",
       "   485   2966.1 MiB      0.0 MiB           1                   self.sample_ix_df['channel'] = [self.selected_columns] * len(self.sample_ix_df)\n",
       "   486                                                         #self.sample_ix_df['channel'] = self.sample_ix_df['channel'].astype('int16')\n",
       "   487   2966.1 MiB      0.0 MiB           1                   key_cols.insert(2, 'channel')\n",
       "   488   2966.1 MiB      0.0 MiB           1                   self.k_select_offset += 1\n",
       "   489   2966.1 MiB      0.0 MiB           1                   self.logger.debug(\"exploding sensor data - does this take a while?\")\n",
       "   490   4435.2 MiB   1469.1 MiB           1                   self.sample_ix_df = self.sample_ix_df.explode('channel')\n",
       "   491                                         \n",
       "   492   4435.2 MiB      0.0 MiB           1               self.key_cols = key_cols\n",
       "   493                                         \n",
       "   494   4435.2 MiB      0.0 MiB           1               self.logger.info(\"Converting dataframe to a flat list of key variables (self.flat_keys)\")\n",
       "   495   5609.4 MiB   1174.2 MiB           1               self.ixed_sample_ix_df = self.sample_ix_df.set_index(key_cols).sort_index()\n",
       "   496                                                     #key_df = self.sample_ix_df[self.key_cols]\n",
       "   497   5609.4 MiB      0.0 MiB           1               self.flat_keys = self.ixed_sample_ix_df.index\n",
       "   498                                                     #self.flat_keys = np.array(list(zip(key_df.to_records(index=False).tolist(),\n",
       "   499                                                     #                                   key_df.iloc[:, k_select_offset:].to_records(index=False).tolist())),\n",
       "   500                                                     #                          dtype='object')\n",
       "   501   5609.4 MiB      0.0 MiB           1               self.logger.info(f\"Extracting mapping of ({key_cols})->indices\")\n",
       "   502   5609.4 MiB      0.0 MiB           1               self.flat_index_map = self.ixed_sample_ix_df.indices#.to_dict()\n",
       "   503   5609.4 MiB      0.0 MiB           1               self.flat_ix_map = self.ixed_sample_ix_df.start_ix\n",
       "   504                                         \n",
       "   505                                                     # ## END NEW VERSION\n",
       "   506                                         \n",
       "   507   5609.4 MiB      0.0 MiB           1               self.logger.info(f\"Length of flat index map: {len(self.flat_index_map)}\")\n",
       "   508                                         \n",
       "   509                                                     ###-----\n",
       "   510   5609.4 MiB      0.0 MiB           1               assert self.sensor_count == len(self.selected_columns)\n",
       "   511   5609.4 MiB      0.0 MiB           1               self.logger.info(f\"Selected {len(self.selected_columns)} sensors\")\n",
       "   512                                                     ###-----\n",
       "   513                                         \n",
       "   514   5609.4 MiB      0.0 MiB           1               self.sensor_selection_trf = pipeline.ApplySensorSelection(selection=self.selected_columns)\n",
       "   515   5980.0 MiB    370.6 MiB           6               self.data_maps = {l_p_s_t_tuple: self.sensor_selection_trf.transform(mat_d)\n",
       "   516   5609.4 MiB      0.0 MiB           3                                 for l_p_s_t_tuple, mat_d in tqdm(self.data_maps.items(),\n",
       "   517   5609.4 MiB      0.0 MiB           1                                                                  desc='Applying sensor selection')}\n",
       "   518                                         \n",
       "   519                                                 else:\n",
       "   520                                                     # print(\"Warning: using naive shared-referencing across objects - only use when feeling lazy\")\n",
       "   521                                                     self.logger.warning(\"Warning: using naive shared-referencing across objects - only use when feeling lazy\")\n",
       "   522                                                     # self.mfcc_m = self.data_from.mfcc_m\n",
       "   523                                                     self.data_maps = self.data_from.data_maps\n",
       "   524                                                     self.n_samples_per_window = self.data_from.n_samples_per_window\n",
       "   525                                                     self.sample_index_maps = self.data_from.sample_index_maps\n",
       "   526                                                     self.flat_index_map = self.data_from.flat_index_map\n",
       "   527                                                     self.flat_ix_map = self.data_from.flat_ix_map\n",
       "   528                                                     self.flat_keys = self.data_from.flat_keys\n",
       "   529                                                     self.key_cols = self.data_from.key_cols\n",
       "   530                                                     self.k_select_offset = self.data_from.k_select_offset\n",
       "   531                                                     # self.logger.info(\"Copying over sample ix dataframe\")\n",
       "   532                                                     self.sample_ix_df = self.data_from.sample_ix_df.copy()\n",
       "   533                                                     self.ixed_sample_ix_df = self.data_from.ixed_sample_ix_df.copy()\n",
       "   534                                                     self.selected_columns = self.data_from.selected_columns\n",
       "   535                                                     self.flatten_sensors_to_samples = self.data_from.flatten_sensors_to_samples\n",
       "   536                                                     self.extra_output_keys = self.data_from.extra_output_keys\n",
       "   537                                                     self.fs_signal = self.data_from.fs_signal\n",
       "   538                                         \n",
       "   539   5980.0 MiB      0.0 MiB           1           self.select(self.selected_flat_indices)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f datasets.HarvardSentences.initialize datasets.HarvardSentences(hvs_test_tuples, pre_processing_pipeline='region_classification', \\\n",
    "                                                                         flatten_sensors_to_samples=True, extra_output_keys='sensor_ras_coord_arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ee920-5520-465b-b478-29f6183a204f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4f5ab-b7a6-4a97-bffa-04918f9716a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
