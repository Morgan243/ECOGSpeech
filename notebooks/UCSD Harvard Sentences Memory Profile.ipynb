{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f064429-ffc8-4623-8e89-a101f621361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecog_speech import datasets, experiments, result_parsing, utils, feature_processing, pipeline, plot_label_regions\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448dbf37-951b-4da9-af9c-b2f665a90c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvs_test_tuples = datasets.HarvardSentences.make_tuples_from_sets_str('UCSD-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02780c60-9665-4815-9214-ff68778ca039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41d6241-724f-4107-ab2e-126ee15a19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 16:56:54,202 - ecog_speech.datasets.HarvardSentences.__attrs_post_init__:337 - DEBUG - preparing pipeline\n",
      "2022-07-09 16:56:54,206 - ecog_speech.datasets.HarvardSentences.__attrs_post_init__:340 - DEBUG - Available pipelines: ['random_sample', 'audio_gate', 'region_classification', 'region_classification_from_word_stim', 'audio_gate_speaking_only', 'default']\n",
      "2022-07-09 16:56:54,207 - ecog_speech.datasets.HarvardSentences.initialize:353 - INFO - 'region_classification' pipeline selected\n",
      "2022-07-09 16:56:54,209 - ecog_speech.datasets.HarvardSentences.initialize:367 - INFO - Loading data directly\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54a3f3eec9c4bc59fd71c2ee2f8af97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 16:56:54,328 - ecog_speech.datasets.HarvardSentences.load_data:762 - INFO - -----------Subset: Data------------\n",
      "2022-07-09 16:56:54,329 - ecog_speech.datasets.HarvardSentences.load_data:763 - INFO - ---28-1-1-UCSD---\n",
      "2022-07-09 16:56:54,330 - ecog_speech.datasets.HarvardSentences.make_filename:1204 - INFO - Harvard sentences only uses location and patient identifiers\n",
      "2022-07-09 16:56:54,331 - ecog_speech.datasets.HarvardSentences.load_data:766 - DEBUG - Path : /home/morgan/Projects/CMSCResearch/ECOGSpeech/ecog_speech/../data/HarvardSentences/UCSD/Data/UCSD28_Task_1.mat\n",
      "2022-07-09 16:56:54,458 - ecog_speech.datasets.HarvardSentences.load_mat_from_path:731 - INFO - Couldn't load UCSD28_Task_1.mat with scipy (vers > 7.3?) - using package 'mat73' to load\n",
      "2022-07-09 16:57:24,387 - ecog_speech.datasets.HarvardSentences.load_data:769 - DEBUG - Matlab keys : ['EKG_signal', 'Labels', 'audio', 'fs_audio', 'fs_signal', 'label_contact_common', 'label_contact_r_a_s', 'sEEG_signal', 'start_stop_word_ms', 'stimcode']\n",
      "2022-07-09 16:57:24,398 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:45 - DEBUG - Accessing fs_signal\n",
      "2022-07-09 16:57:24,399 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:52 - DEBUG - Input source frequency, fs object: 1024.0\n",
      "2022-07-09 16:57:24,454 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:71 - INFO - sEEG_signal@1024, shape: (900001, 108), [(Timedelta('0 days 00:00:00'), Timedelta('0 days 00:14:38.906250'))]\n",
      "2022-07-09 16:57:24,504 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.transform:22 - DEBUG - Updated keys: {'fs_signal', 'signal'}\n",
      "2022-07-09 16:57:24,505 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:45 - DEBUG - Accessing fs_audio\n",
      "2022-07-09 16:57:24,508 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:52 - DEBUG - Input source frequency, fs object: 48000.0\n",
      "2022-07-09 16:57:39,328 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:71 - INFO - audio@48000, shape: (42187547,), [(Timedelta('0 days 00:00:00'), Timedelta('0 days 00:14:38.907208333'))]\n",
      "2022-07-09 16:57:48,348 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.transform:22 - DEBUG - Updated keys: {'fs_audio', 'audio'}\n",
      "2022-07-09 16:57:48,350 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:45 - DEBUG - Accessing fs_signal\n",
      "2022-07-09 16:57:48,351 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:52 - DEBUG - Input source frequency, fs object: 1024\n",
      "2022-07-09 16:57:49,009 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.process:71 - INFO - stimcode@1024, shape: (900001,), [(Timedelta('0 days 00:00:00'), Timedelta('0 days 00:14:38.906250'))]\n",
      "2022-07-09 16:57:49,041 - ecog_speech.pipeline.ParseTimeSeriesArrToFrame.transform:22 - DEBUG - Updated keys: {'stim', 'fs_signal'}\n",
      "2022-07-09 16:57:49,054 - ecog_speech.pipeline.ParseSensorRAS.transform:22 - DEBUG - Updated keys: {'sensor_ras_coord_arr', 'sensor_ras_df'}\n",
      "2022-07-09 16:57:49,827 - ecog_speech.pipeline.ExtractMFCC.transform:22 - DEBUG - Updated keys: {'audio_mel_spec'}\n",
      "2022-07-09 16:57:49,828 - ecog_speech.pipeline.IdentifyGoodAndBadSensors.process:90 - WARNING - Electrodes with key 'electrodes' not found among ['EKG_signal', 'Labels', 'audio', 'fs_audio', 'fs_signal', 'label_contact_common', 'label_contact_r_a_s', 'sEEG_signal', 'start_stop_word_ms', 'stimcode', 'signal', 'stim', 'sensor_ras_df', 'sensor_ras_coord_arr', 'audio_mel_spec'] - but on_missing=\"ignore\", so moving on\n",
      "2022-07-09 16:57:49,828 - ecog_speech.pipeline.IdentifyGoodAndBadSensors.transform:22 - DEBUG - Updated keys: {'bad_sensor_columns', 'good_sensor_columns'}\n",
      "2022-07-09 16:57:49,830 - ecog_speech.pipeline.SubsampleSignal.transform:22 - DEBUG - Updated keys: {'stim', 'fs_signal', 'signal'}\n",
      "2022-07-09 16:57:49,938 - ecog_speech.pipeline.SentCodeFromStartStopWordTimes.process:410 - WARNING - Sent code 45.0 has a time range more than a minute: 0 days 00:01:20.365234375\n",
      "2022-07-09 16:57:50,003 - ecog_speech.pipeline.SentCodeFromStartStopWordTimes.transform:22 - DEBUG - Updated keys: {'stim', 'sent_start_stop_time', 'word_start_stop_times'}\n",
      "2022-07-09 16:57:50,143 - ecog_speech.pipeline.NewNewMultiTaskStartStop.process:504 - WARNING - Sent code 20.0 has no future sentence dodes in front of it\n",
      "2022-07-09 16:57:50,612 - ecog_speech.pipeline.NewNewMultiTaskStartStop.transform:22 - DEBUG - Updated keys: {'word_start_stop_times'}\n",
      "2022-07-09 16:57:53,447 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'speaking_word_stim_mask', 'speaking_word_stim'}\n",
      "2022-07-09 16:57:56,482 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'listening_word_stim', 'listening_word_stim_mask'}\n",
      "2022-07-09 16:57:59,748 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'mouthing_word_stim', 'mouthing_word_stim_mask'}\n",
      "2022-07-09 16:58:02,885 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'imagining_word_stim_mask', 'imagining_word_stim'}\n",
      "2022-07-09 16:58:04,061 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'speaking_region_stim_mask', 'speaking_region_stim'}\n",
      "2022-07-09 16:58:05,446 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'listening_region_stim_mask', 'listening_region_stim'}\n",
      "2022-07-09 16:58:06,550 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'mouthing_region_stim', 'mouthing_region_stim_mask'}\n",
      "2022-07-09 16:58:07,790 - ecog_speech.pipeline.NewStimFromRegionStartStopTimes.transform:22 - DEBUG - Updated keys: {'imagining_region_stim', 'imagining_region_stim_mask'}\n",
      "2022-07-09 16:58:07,791 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-09 16:58:07,792 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5b8a4ed3fd42b2b1994be5e21e1b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'speaking_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 16:59:02,329 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-09 16:59:02,330 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 0\n",
      "2022-07-09 16:59:02,331 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-09 16:59:02,331 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-09 16:59:02,332 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79311db187a84e7e89ad89b02ce1a524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'listening_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 17:00:10,143 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-09 17:00:10,144 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 1\n",
      "2022-07-09 17:00:10,145 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-09 17:00:10,146 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-09 17:00:10,147 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c2a911ba0b4a139c3eca2defa2f415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'mouthing_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 17:01:06,328 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-09 17:01:06,329 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 2\n",
      "2022-07-09 17:01:06,330 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-09 17:01:06,330 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1104 - INFO - (512, Timedelta('0 days 00:00:00.500000'))\n",
      "2022-07-09 17:01:06,331 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1105 - INFO - Samples per window: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ff4d850b7c493e9ea315523a9b8e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stim regions from 'imagining_region_stim':   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 17:02:00,943 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1167 - INFO - Number of samples keys in sample index: {50000: 1}\n",
      "2022-07-09 17:02:00,943 - ecog_speech.pipeline.WindowSampleIndicesFromStim.process:1168 - INFO - Windows coded to (i.e. target value): 3\n",
      "2022-07-09 17:02:00,944 - ecog_speech.pipeline.WindowSampleIndicesFromStim.transform:22 - DEBUG - Updated keys: {'n_samples_per_window', 'sample_index_map', 'index_source_map'}\n",
      "2022-07-09 17:02:00,946 - ecog_speech.datasets.HarvardSentences.initialize:397 - INFO - N samples per window: 256\n",
      "2022-07-09 17:02:00,948 - ecog_speech.datasets.HarvardSentences.initialize:417 - INFO - GOOD AND BAD SENSORS: {('UCSD', 28, 1, 1): ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107], None)}\n",
      "2022-07-09 17:02:00,959 - ecog_speech.datasets.HarvardSentences.initialize:434 - INFO - Selected 108 columns using union method: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107\n",
      "2022-07-09 17:02:00,961 - ecog_speech.datasets.HarvardSentences.initialize:450 - INFO - Processing participant ('UCSD', 28, 1, 1) index, having keys: [0, 1, 2, 3]\n",
      "2022-07-09 17:02:48,087 - ecog_speech.datasets.HarvardSentences.initialize:467 - INFO - word_start_stop_times found aligning all index start times to a sentence code\n",
      "2022-07-09 17:02:48,169 - ecog_speech.datasets.HarvardSentences.initialize:474 - INFO - Combining all of 1 index frames\n",
      "2022-07-09 17:02:48,192 - ecog_speech.datasets.HarvardSentences.initialize:478 - INFO - flatten_sensors_to_samples selected - creating channel/sensor labels for samples\n",
      "2022-07-09 17:02:48,241 - ecog_speech.datasets.HarvardSentences.initialize:483 - DEBUG - exploding sensor data - does this take a while?\n",
      "2022-07-09 17:02:59,378 - ecog_speech.datasets.HarvardSentences.initialize:488 - INFO - Converting dataframe to a flat list of key variables (self.flat_keys)\n",
      "2022-07-09 17:03:47,039 - ecog_speech.datasets.HarvardSentences.initialize:493 - INFO - Extracting mapping of (['label', 'sample_ix', 'channel', 'location', 'patient', 'session', 'trial'])->indices\n",
      "2022-07-09 17:06:22,967 - ecog_speech.datasets.HarvardSentences.initialize:498 - INFO - Length of flat index map: 21600000\n",
      "2022-07-09 17:06:22,968 - ecog_speech.datasets.HarvardSentences.initialize:502 - INFO - Selected 108 sensors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2675c7cb6c48c2a78b72861e98ad42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying sensor selection:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 17:06:23,512 - ecog_speech.pipeline.ApplySensorSelection.process:142 - INFO - Selection of columns passed to sensor selection\n",
      "2022-07-09 17:06:24,854 - ecog_speech.pipeline.ApplySensorSelection.process:167 - INFO - Selecting columns in RAS coordinate data\n",
      "2022-07-09 17:06:24,858 - ecog_speech.pipeline.ApplySensorSelection.transform:22 - DEBUG - Updated keys: {'bad_columns', 'signal', 'sensor_ras_coord_arr', 'sensor_ras_df', 'bad_sensor_method', 'selected_columns'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /home/morgan/Projects/CMSCResearch/ECOGSpeech/ecog_speech/datasets.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "   345    356.6 MiB    356.6 MiB           1       def initialize(self):\n",
       "   346                                         \n",
       "   347                                                 # If nothing passed, use 'default' pipeline\n",
       "   348    356.6 MiB      0.0 MiB           1           if self.pre_processing_pipeline is None:\n",
       "   349                                                     self.logger.info(\"Default pipeline selected\")\n",
       "   350                                                     self.pipeline_f = self.pipeline_map['default']\n",
       "   351                                                 # If string passed, use it to select the pipeline in the map\n",
       "   352    356.6 MiB      0.0 MiB           1           elif isinstance(self.pre_processing_pipeline, str):\n",
       "   353    356.6 MiB      0.0 MiB           1               self.logger.info(f\"'{self.pre_processing_pipeline}' pipeline selected\")\n",
       "   354    356.6 MiB      0.0 MiB           1               self.pipeline_f = self.pipeline_map[self.pre_processing_pipeline]\n",
       "   355                                                 # Otherwise, just assume it will work, that a callable is passed\n",
       "   356                                                 # TODO: Check that pipeline_f is callable\n",
       "   357                                                 else:\n",
       "   358                                                     self.logger.info(f\"{str(self.pre_processing_pipeline)} pipeline passed directly\")\n",
       "   359                                                     self.pipeline_f = self.pre_processing_pipeline\n",
       "   360                                         \n",
       "   361    356.6 MiB      0.0 MiB           1           if isinstance(self.pipeline_f, Pipeline):\n",
       "   362    356.6 MiB      0.0 MiB           1               self.pipeline_obj = self.pipeline_f\n",
       "   363    356.6 MiB      0.0 MiB           1               self.pipeline_f = self.pipeline_obj.transform\n",
       "   364                                         \n",
       "   365                                                 # If no data sharing, then load and parse data from scratch\n",
       "   366    356.6 MiB      0.0 MiB           1           if self.data_from is None:\n",
       "   367    356.6 MiB      0.0 MiB           1               self.logger.info(\"Loading data directly\")\n",
       "   368                                                     # Leave this here for now...\n",
       "   369                                                     # self.mfcc_m = torchaudio.transforms.MFCC(self.default_audio_sample_rate,\n",
       "   370                                                     #                                         self.num_mfcc)\n",
       "   371                                         \n",
       "   372                                                     ## Data loading ##\n",
       "   373                                                     # - Load the data, parsing into pandas data frame/series types\n",
       "   374                                                     # - Only minimal processing into Python objects done here\n",
       "   375    356.7 MiB      0.1 MiB           1               data_iter = tqdm(self.patient_tuples, desc=\"Loading data\")\n",
       "   376   1507.1 MiB   1150.4 MiB           7               mat_data_maps = {l_p_s_t_tuple: self.load_data(*l_p_s_t_tuple,\n",
       "   377                                                                                                    # sensor_columns=self.sensor_columns,\n",
       "   378                                                                                                    # IMPORTANT: Don't parse data yet\n",
       "   379                                                                                                    # parse_mat_data=False,\n",
       "   380    356.7 MiB      0.0 MiB           1                                                              subset=self.data_subset)\n",
       "   381    356.7 MiB      0.0 MiB           2                                for l_p_s_t_tuple in data_iter}\n",
       "   382                                         \n",
       "   383                                                     #  Important processing  #\n",
       "   384                                                     # - Process each subject in data map through pipeline func\n",
       "   385   1507.1 MiB      0.0 MiB           1               self.sample_index_maps = dict()\n",
       "   386   1507.1 MiB      0.0 MiB           1               self.data_maps = dict()\n",
       "   387                                         \n",
       "   388   3021.2 MiB      0.0 MiB           2               for k, dmap in mat_data_maps.items():\n",
       "   389                                                         # Run the pipeline, mutating/modifying the data map for this patient trial\n",
       "   390   3021.2 MiB   1514.1 MiB           1                   res_dmap = self.pipeline_f(dmap)\n",
       "   391   3021.2 MiB      0.0 MiB           1                   self.sample_index_maps[k] = res_dmap['sample_index_map']\n",
       "   392                                                         # THe first data map sets the sampling frequency fs\n",
       "   393                                                         # self.fs_signal = getattr(self, 'fs_signal', res_dmap[self.mat_d_keys['signal_fs']])\n",
       "   394   3021.2 MiB      0.0 MiB           1                   self.fs_signal = res_dmap[self.mat_d_keys['signal_fs']] if self.fs_signal is None else self.fs_signal\n",
       "   395                                         \n",
       "   396   3021.2 MiB      0.0 MiB           1                   self.n_samples_per_window = getattr(self, 'n_samples_per_window', res_dmap['n_samples_per_window'])\n",
       "   397   3021.2 MiB      0.0 MiB           1                   self.logger.info(f\"N samples per window: {self.n_samples_per_window}\")\n",
       "   398                                         \n",
       "   399   3021.2 MiB      0.0 MiB           1                   if self.fs_signal != res_dmap[self.mat_d_keys['signal_fs']]:\n",
       "   400                                                             raise ValueError(\"Mismatch fs (%s!=%s) on %s\" % (self.fs_signal, res_dmap['fs_signal'], str(k)))\n",
       "   401                                         \n",
       "   402   3021.2 MiB      0.0 MiB           1                   self.data_maps[k] = res_dmap\n",
       "   403                                         \n",
       "   404                                                     ###\n",
       "   405                                                     # Sensor selection logic - based on the patients loaded - which sensors do we use?\n",
       "   406   3021.2 MiB      0.0 MiB           1               if self.sensor_columns is None or isinstance(self.sensor_columns, str):\n",
       "   407                                                         # good_and_bad_tuple_d = {l_p_s_t_tuple: self.identify_good_and_bad_sensors(mat_d, self.sensor_columns)\n",
       "   408                                                         #                            for l_p_s_t_tuple, mat_d in mat_data_maps.items()}\n",
       "   409   3021.2 MiB      0.0 MiB           6                   good_and_bad_tuple_d = {l_p_s_t_tuple: (mat_d['good_sensor_columns'], mat_d['bad_sensor_columns'])\n",
       "   410   3021.2 MiB      0.0 MiB           2                                           for l_p_s_t_tuple, mat_d in self.data_maps.items()}\n",
       "   411                                         \n",
       "   412   3021.2 MiB      0.0 MiB           5                   good_and_bad_tuple_d = {\n",
       "   413   3021.2 MiB      0.0 MiB           2                       k: (set(gs) if gs else (list(range(self.data_maps[k][self.mat_d_keys['signal']].shape[1]))),\n",
       "   414   3021.2 MiB      0.0 MiB           1                           bs)\n",
       "   415   3021.2 MiB      0.0 MiB           2                       for k, (gs, bs) in good_and_bad_tuple_d.items()}\n",
       "   416                                         \n",
       "   417   3021.2 MiB      0.0 MiB           1                   self.logger.info(\"GOOD AND BAD SENSORS: \" + str(good_and_bad_tuple_d))\n",
       "   418   3021.2 MiB      0.0 MiB           1                   self.sensor_columns = 'union' if self.sensor_columns is None else self.sensor_columns\n",
       "   419                                         \n",
       "   420                                                         # UNION: Select all good sensors from all inputs, zeros will be filled for those missing\n",
       "   421   3021.2 MiB      0.0 MiB           1                   if self.sensor_columns == 'union':\n",
       "   422   3021.2 MiB      0.0 MiB         112                       self.selected_columns = sorted(list({_gs for k, (gs, bs) in good_and_bad_tuple_d.items()\n",
       "   423   3021.2 MiB      0.0 MiB         109                                                            for _gs in gs}))\n",
       "   424                                                         # INTERSECTION: Select only sensors that are rated good in all inputs\n",
       "   425                                                         elif self.sensor_columns == 'intersection' or self.sensor_columns == 'valid':\n",
       "   426                                                             s = [set(gs) for k, (gs, bs) in good_and_bad_tuple_d.items()]\n",
       "   427                                                             self.selected_columns = sorted(list(s[0].intersection(*s[1:])))\n",
       "   428                                         \n",
       "   429                                                         # elif self.sensor_columns == 'all':\n",
       "   430                                                         else:\n",
       "   431                                                             raise ValueError(\"Unknown snsor columns argument: \" + str(self.sensor_columns))\n",
       "   432                                                         # print(\"Selected columns with -%s- method: %s\"\n",
       "   433                                                         #      % (self.sensor_columns, \", \".join(map(str, self.selected_columns))) )\n",
       "   434   3021.2 MiB      0.0 MiB           2                   self.logger.info(f\"Selected {len(self.selected_columns)} columns using {self.sensor_columns} method: \"\n",
       "   435   3021.2 MiB      0.0 MiB           1                                    f\"{', '.join(map(str, self.selected_columns))}\")\n",
       "   436                                                         #self.logger.info(\"Selected columns with -%s- method: %s\"\n",
       "   437                                                         #                 % (self.sensor_columns, \", \".join(map(str, self.selected_columns))))\n",
       "   438                                                     else:\n",
       "   439                                                         self.selected_columns = self.sensor_columns\n",
       "   440                                         \n",
       "   441   3021.2 MiB      0.0 MiB           1               self.sensor_count = len(self.selected_columns)\n",
       "   442                                         \n",
       "   443                                                     # ### New Version ###\n",
       "   444   3021.2 MiB      0.0 MiB           1               sample_ix_df_l = list()\n",
       "   445   3021.2 MiB      0.0 MiB           2               key_col_dtypes = {'label': 'int8', 'sample_ix': 'int32', 'location': 'string',\n",
       "   446   3021.2 MiB      0.0 MiB           1                                'patient': 'int8', 'session': 'int8', 'trial': 'int8'}\n",
       "   447   3021.2 MiB      0.0 MiB           1               key_cols = list(key_col_dtypes.keys())\n",
       "   448                                         \n",
       "   449   3245.8 MiB      0.0 MiB           2               for l_p_s_t, index_map in self.sample_index_maps.items():\n",
       "   450   3021.2 MiB      0.0 MiB           1                   self.logger.info(f\"Processing participant {l_p_s_t} index, having keys: {list(index_map.keys())}\")\n",
       "   451                                                         #self.logger.info(f\"Creating participants index frame: {l_p_s_t}\")\n",
       "   452   3021.2 MiB      0.0 MiB           1                   patient_ixes = list()\n",
       "   453                                         \n",
       "   454   3021.2 MiB      0.0 MiB           1                   cols = key_cols + ['start_t', 'stop_t', 'indices']\n",
       "   455                                         \n",
       "   456   3021.2 MiB      0.0 MiB           1                   key_l = list(l_p_s_t)\n",
       "   457                                         \n",
       "   458   3197.8 MiB    169.4 MiB      200008                   patient_ixes += [tuple([label_code, ix_i] + key_l + [_ix.min(), _ix.max(), _ix])\n",
       "   459   3153.7 MiB      0.0 MiB           5                                    for label_code, indices_l in index_map.items()\n",
       "   460   3197.8 MiB      7.2 MiB      200004                                    for ix_i, _ix in enumerate(indices_l)]\n",
       "   461                                         \n",
       "   462   3245.7 MiB     47.9 MiB           1                   p_ix_df = pd.DataFrame(patient_ixes, columns=cols)\n",
       "   463   3245.7 MiB      0.0 MiB           1                   p_ix_df = p_ix_df.astype(key_col_dtypes)\n",
       "   464                                         \n",
       "   465                                                         # #TODO: Is this still necessary? Determining the sentence code for every window sample from scratch\n",
       "   466   3245.7 MiB      0.0 MiB           1                   if 'word_start_stop_times' in self.data_maps[l_p_s_t]:\n",
       "   467   3245.7 MiB      0.0 MiB           1                       self.logger.info(f\"word_start_stop_times found aligning all index start times to a sentence code\")\n",
       "   468   3245.7 MiB      0.0 MiB           1                       wsst_df = self.data_maps[l_p_s_t]['word_start_stop_times']\n",
       "   469   3245.7 MiB      0.0 MiB           1                       nearest_ixes = wsst_df.index.get_indexer(p_ix_df.start_t, method='nearest')\n",
       "   470   3245.8 MiB      0.1 MiB           1                       p_ix_df['sent_code'] = wsst_df.iloc[nearest_ixes].stim_sentcode.values\n",
       "   471                                         \n",
       "   472   3245.8 MiB      0.0 MiB           1                   sample_ix_df_l.append(p_ix_df)\n",
       "   473                                         \n",
       "   474   3245.8 MiB      0.0 MiB           1               self.logger.info(f\"Combining all of {len(sample_ix_df_l)} index frames\")\n",
       "   475   3245.8 MiB      0.0 MiB           1               self.sample_ix_df = pd.concat(sample_ix_df_l).reset_index(drop=True)\n",
       "   476   3245.8 MiB      0.0 MiB           1               k_select_offset = 2\n",
       "   477   3245.8 MiB      0.0 MiB           1               if self.flatten_sensors_to_samples:\n",
       "   478   3245.8 MiB      0.0 MiB           1                   self.logger.info(f\"flatten_sensors_to_samples selected - creating channel/sensor labels for samples\")\n",
       "   479   3245.8 MiB      0.0 MiB           1                   self.sample_ix_df['channel'] = [self.selected_columns] * len(self.sample_ix_df)\n",
       "   480                                                         #self.sample_ix_df['channel'] = self.sample_ix_df['channel'].astype('int16')\n",
       "   481   3245.8 MiB      0.0 MiB           1                   key_cols.insert(2, 'channel')\n",
       "   482   3245.8 MiB      0.0 MiB           1                   k_select_offset += 1\n",
       "   483   3245.8 MiB      0.0 MiB           1                   self.logger.debug(\"exploding sensor data - does this take a while?\")\n",
       "   484   4550.8 MiB   1305.0 MiB           1                   self.sample_ix_df = self.sample_ix_df.explode('channel')\n",
       "   485                                         \n",
       "   486   4550.8 MiB      0.0 MiB           1               self.key_cols = key_cols\n",
       "   487                                         \n",
       "   488   4550.8 MiB      0.0 MiB           1               self.logger.info(\"Converting dataframe to a flat list of key variables (self.flat_keys)\")\n",
       "   489   4880.3 MiB    329.5 MiB           1               key_df = self.sample_ix_df[self.key_cols]\n",
       "   490  10747.1 MiB   2840.6 MiB           3               self.flat_keys = np.array(list(zip(key_df.to_records(index=False).tolist(),\n",
       "   491   9572.6 MiB   1852.3 MiB           1                                                  key_df.iloc[:, k_select_offset:].to_records(index=False).tolist())),\n",
       "   492  10747.1 MiB      0.0 MiB           1                                         dtype='object')\n",
       "   493   9573.2 MiB  -1173.9 MiB           1               self.logger.info(f\"Extracting mapping of ({key_cols})->indices\")\n",
       "   494  12887.8 MiB   3314.6 MiB           1               self.flat_index_map = self.sample_ix_df.set_index(key_cols).indices.to_dict()\n",
       "   495                                         \n",
       "   496                                                     # ## END NEW VERSION\n",
       "   497                                         \n",
       "   498  12887.8 MiB      0.0 MiB           1               self.logger.info(f\"Length of flat index map: {len(self.flat_index_map)}\")\n",
       "   499                                         \n",
       "   500                                                     ###-----\n",
       "   501  12887.8 MiB      0.0 MiB           1               assert self.sensor_count == len(self.selected_columns)\n",
       "   502  12887.8 MiB      0.0 MiB           1               self.logger.info(f\"Selected {len(self.selected_columns)} sensors\")\n",
       "   503                                                     ###-----\n",
       "   504                                         \n",
       "   505  12887.8 MiB      0.0 MiB           1               self.sensor_selection_trf = pipeline.ApplySensorSelection(selection=self.selected_columns)\n",
       "   506  13258.5 MiB    370.7 MiB           6               self.data_maps = {l_p_s_t_tuple: self.sensor_selection_trf.transform(mat_d)\n",
       "   507  12887.8 MiB      0.0 MiB           3                                 for l_p_s_t_tuple, mat_d in tqdm(self.data_maps.items(),\n",
       "   508  12887.8 MiB      0.0 MiB           1                                                                  desc='Applying sensor selection')}\n",
       "   509                                         \n",
       "   510                                                 else:\n",
       "   511                                                     # print(\"Warning: using naive shared-referencing across objects - only use when feeling lazy\")\n",
       "   512                                                     self.logger.warning(\"Warning: using naive shared-referencing across objects - only use when feeling lazy\")\n",
       "   513                                                     # self.mfcc_m = self.data_from.mfcc_m\n",
       "   514                                                     self.data_maps = self.data_from.data_maps\n",
       "   515                                                     self.sample_index_maps = self.data_from.sample_index_maps\n",
       "   516                                                     self.flat_index_map = self.data_from.flat_index_map\n",
       "   517                                                     self.flat_keys = self.data_from.flat_keys\n",
       "   518                                                     self.key_cols = self.data_from.key_cols\n",
       "   519                                                     # self.logger.info(\"Copying over sample ix dataframe\")\n",
       "   520                                                     self.sample_ix_df = self.data_from.sample_ix_df.copy()\n",
       "   521                                                     self.selected_columns = self.data_from.selected_columns\n",
       "   522                                                     self.flatten_sensors_to_samples = self.data_from.flatten_sensors_to_samples\n",
       "   523                                                     self.extra_output_keys = self.data_from.extra_output_keys\n",
       "   524                                                     self.fs_signal = self.data_from.fs_signal\n",
       "   525                                         \n",
       "   526  13258.5 MiB      0.0 MiB           1           self.select(self.selected_flat_indices)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f datasets.HarvardSentences.initialize datasets.HarvardSentences(hvs_test_tuples, pre_processing_pipeline='region_classification', \\\n",
    "                                                                         flatten_sensors_to_samples=True, extra_output_keys='sensor_ras_coord_arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a11da-fd90-469c-b298-e30952ce6e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4ec31-edf0-47cd-8b4d-045dc50f13e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ee920-5520-465b-b478-29f6183a204f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4f5ab-b7a6-4a97-bffa-04918f9716a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
